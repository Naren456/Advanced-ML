# Class 19: Time Series Analysis - 2

## 1. Forecasting Framework

### Train-Test Split in Time Series
Unlike standard Machine Learning where data is shuffled, Time Series data **must preserve order**.
*   **Method**: Split sequentially.
    *   **Train Set**: Past data (e.g., first 80% or first 18 years).
    *   **Test Set**: Future data (e.g., last 20% or next 12 months).
*   **Why?**: Shuffling destroys the time dependence (autocorrelation) which is the core of Time Series analysis. We generally don't have separate `X` and `y` features in the simplest univariate case; we predict future `Y` based on past `Y`.

### Evaluation Metric: MAPE
*   **MAPE (Mean Absolute Percentage Error)**:
    $$ MAPE = \frac{1}{n} \sum \left| \frac{Actual - Forecast}{Actual} \right| \times 100 $$
*   **Why MAPE?**:
    *   **Interpretable**: Gives error in percentage terms (e.g., "Our forecast is off by 5%").
    *   **Business Friendly**: Easier to explain to stakeholders than MSE or RMSE.
*   **Consequences of Bad Forecasting**:
    *   **Under-forecast**: Stock shortages, lost sales, poor customer experience.
    *   **Over-forecast**: Inventory loss, high storage costs, wastage.

## 2. Data Preprocessing

### Handling Missing Values
*   **Problem**: Real-world data often has gaps.
*   **Bad Approach**: Imputing with the global **Mean**. This flat-lines the data and ignores trends/seasonality.
*   **Better Approach**: **Linear Interpolation**.
    *   Fills missing values by connecting the point before and the point after with a straight line.
    *   Preserves the local trend.
    *   *Notebook Implementation*:
        ```python
        # Linear Interpolation
        mobile_sales = mobile_sales.interpolate(method='linear')
        ```

## 3. Basic Forecasting Models (Benchmarks)

These simple models define the "baseline" performance. Any complex model (ARIMA, LSTM, etc.) must beat these to be worth the effort.

### A. Simple Mean Forecast
*   **Concept**: Forecast all future values as the average of *all* historical data.
*   **Result**: A horizontal straight line.
*   **Pros/Cons**: Very stable but ignores everything (trend, seasonality, recent changes).

### B. Naive Approach
*   **Concept**: "Tomorrow will be exactly the same as today."
*   **Formula**: $\hat{Y}_{t+1} = Y_t$
*   **Application**: Takes the **last observed value** of the train set and forecasts it forward.
*   **Pros/Cons**: Responsive to the latest level but assumes no trend or seasonality.
*   **Notebook Code**:
    ```python
    test_x['pred'] = train_x.Sales[-1]
    ```

### C. Seasonal Naive Approach
*   **Concept**: "This season will be like the same season last year."
*   **Application**: Useful for highly seasonal data (e.g., woolen clothes sales peak in winter).
*   **Formula**: $\hat{Y}_{t} = Y_{t-m}$ (where $m$ is the seasonal period).
*   **Pros/Cons**: Captures seasonality perfectly but misses trend.

### D. Drift Method
*   **Concept**: Draws specific line from the very first point to the very last point of the training data and extrapolates that slope.
*   **Formula**: 
    $$ \text{Slope} (m) = \frac{Y_{last} - Y_{first}}{\text{Total Time Steps}} $$
    $$ \hat{Y}_{t+h} = Y_{last} + m \times h $$
*   **Pros/Cons**: Captures the global trend but misses seasonality. Extremely sensitive to outliers at the start/end points.
*   **Notebook Code**:
    ```python
    y_t = train_x['Sales'][-1]
    y_0 = train_x['Sales'][0]
    m = (y_t - y_0) / len(train_x)
    # Forecast is generated by adding m * step to y_t
    ```

## 4. Introduction to Smoothing Methods
(Theory introduced, practical implementation typically follows in advanced sessions)

*   **Simple Exponential Smoothing (SES)**: Weighted average where recent observations get more weight. Good for data with no trend/seasonality.
*   **Holtâ€™s Linear Trend**: Extension of SES to capture **Trend**.
*   **Holt-Winters (Triple Exponential Smoothing)**: Extension to capture both **Trend** and **Seasonality**.
